# docker-compose.prod.yml
# Production configuration - use with base docker-compose.yml
# Usage: docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

services:
  # =================================================================
  # Message Broker - Kafka (Production)
  # =================================================================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: ml-kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_COMPRESSION_TYPE: snappy
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: ml-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # =================================================================
  # MLflow Database - Override for Production
  # =================================================================
  mlflow-db:
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    restart: unless-stopped

  # =================================================================
  # MLflow Artifact Store - S3 (Production uses real S3/GCS)
  # For production, comment this out and use real cloud storage
  # =================================================================
  # mlflow-minio is not included in production - use real S3/GCS

  # =================================================================
  # MLflow Tracking Server - Production Override
  # =================================================================
  mlflow-server:
    ports:
      - "5000:5000"
    environment:
      MLFLOW_BACKEND_STORE_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@mlflow-db:5432/${POSTGRES_DB}
      MLFLOW_ARTIFACT_ROOT: ${MLFLOW_ARTIFACT_ROOT}  # s3://bucket or gs://bucket
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      GCP_PROJECT: ${GCP_PROJECT:-}
      MLFLOW_HOST: 0.0.0.0
    command: >
      sh -c "
        mlflow server
        --host 0.0.0.0
        --port 5000
        --backend-store-uri postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@mlflow-db:5432/${POSTGRES_DB}
        --default-artifact-root ${MLFLOW_ARTIFACT_ROOT}
        --no-serve-artifacts
        --workers 4
      "
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

  # =================================================================
  # Feature Store - Redis Production Override
  # =================================================================
  redis:
    ports:
      - "6379:6379"
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
    command: >
      sh -c "
        if [ -z '${REDIS_PASSWORD}' ]; then
          redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
        else
          redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru --requirepass ${REDIS_PASSWORD}
        fi
      "
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1.5G

  # =================================================================
  # Model API - Production Override
  # =================================================================
  model-api:
    ports:
      - "8000:8000"
    environment:
      ENVIRONMENT: production
      MLFLOW_TRACKING_URI: "http://mlflow-server:5000"
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      GCP_PROJECT: ${GCP_PROJECT:-}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOG_LEVEL: INFO
      API_RELOAD: "false"
      API_WORKERS: 4
      PRELOAD_MODELS: ${PRELOAD_MODELS}
      MODEL_AUTO_UPDATE: "true"
      MODEL_UPDATE_INTERVAL: "60"
      MODEL_CACHE_SIZE: "10"
      FEATURE_CACHE_TTL: "7200"
    volumes:
      - ./model_cache:/model_cache
    depends_on:
      kafka:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

  # =================================================================
  # Monitoring - Prometheus Production Override
  # =================================================================
  prometheus:
    ports:
      - "9090:9090"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  # =================================================================
  # Monitoring - Grafana Production Override
  # =================================================================
  grafana:
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-worldmap-panel
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: ${GRAFANA_ROOT_URL:-http://localhost:3000}
      GF_SMTP_ENABLED: ${GF_SMTP_ENABLED:-false}
      GF_SMTP_HOST: ${GF_SMTP_HOST:-}
      GF_SMTP_USER: ${GF_SMTP_USER:-}
      GF_SMTP_PASSWORD: ${GF_SMTP_PASSWORD:-}
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  # =================================================================
  # Apache Beam Runner - Production (Cloud Dataflow/EMR)
  # =================================================================
  beam-runner:
    build:
      context: .
      dockerfile: docker/beam/Dockerfile
    container_name: ml-beam-runner
    environment:
      BEAM_RUNNER: ${BEAM_RUNNER:-DataflowRunner}  # Or FlinkRunner
      GCP_PROJECT: ${GCP_PROJECT}
      GCP_REGION: ${GCP_REGION:-us-central1}
      GCP_TEMP_LOCATION: ${GCP_TEMP_LOCATION}
      GCP_STAGING_LOCATION: ${GCP_STAGING_LOCATION}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      PYTHONPATH: /app
      MLFLOW_TRACKING_URI: http://mlflow-server:5000
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    volumes:
      - ./src:/app/src:ro
      - ./configs:/app/configs:ro
      - ${GOOGLE_APPLICATION_CREDENTIALS:-./credentials/gcp-key.json}:/app/gcp-key.json:ro
    depends_on:
      kafka:
        condition: service_healthy
    profiles:
      - beam
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

  # =================================================================
  # NGINX Reverse Proxy (Production Only)
  # =================================================================
  nginx:
    image: nginx:alpine
    container_name: ml-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - model-api
      - mlflow-server
      - grafana
    restart: unless-stopped
    profiles:
      - web

# =================================================================
# Production Volumes
# =================================================================
volumes:
  mlflow_db_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local