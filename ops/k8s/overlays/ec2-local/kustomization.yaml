apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
# Local Docker Desktop Kubernetes overlay
# Used by scripts/demo/demo-local-k8s/demo-local-k8s.sh
# Requires locally-built images: ml-pipeline/api:v1.0.0, ml-pipeline/mlflow:v1.0.0
# NodePorts: MLflow:30000, API:30001, Grafana:30002, Prometheus:30090
namespace: ml-pipeline-prod

resources:
  - ../../base/configmap.yaml
  - ../../base/postgres.yaml
  - ../../base/redis.yaml
  - ../../base/mlflow.yaml
  - ../../base/api.yaml
  - ../../base/monitoring.yaml
  - ../../base/exporters.yaml

secretGenerator:
  - name: ml-pipeline-secrets
    envs:
      - secrets.env
    type: Opaque

# Prometheus and Grafana configs - generated from monitoring source files.
# Paths use ../../../ because this file is at ops/k8s/overlays/ec2-local/
# and monitoring files are at ops/monitoring/ (3 levels up from here).
# The demo script passes --load-restrictor LoadRestrictionsNone to allow cross-boundary refs.
configMapGenerator:
  - name: prometheus-config
    files:
      - ../../../monitoring/prometheus/prometheus.yml
      - ../../../monitoring/prometheus/alerts/alert_rules.yml
      - ../../../monitoring/prometheus/rules/recording_rules.yml
  - name: grafana-config
    files:
      - ../../../monitoring/grafana/datasources/datasources.yaml
      - ../../../monitoring/grafana/dashboards/dashboards.yaml
  - name: grafana-dashboards
    files:
      - ../../../monitoring/grafana/dashboards/model-performance.json
      - ../../../monitoring/grafana/dashboards/feature-store.json
      - ../../../monitoring/grafana/dashboards/system-resources.json
      - ../../../monitoring/grafana/dashboards/data-ingestion.json
      - ../../../monitoring/grafana/dashboards/error-tracking.json
      - ../../../monitoring/grafana/dashboards/apps-uptime.json

generatorOptions:
  disableNameSuffixHash: true

patches:
  # MLflow - use locally built image (imagePullPolicy: Never uses Docker Desktop's local cache)
  - target:
      kind: Deployment
      name: mlflow
    patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: mlflow
      spec:
        template:
          spec:
            containers:
            - name: mlflow
              image: ml-pipeline/mlflow:v1.0.0
              imagePullPolicy: Never
              args:
              - "--backend-store-uri"
              - "postgresql://$(DATABASE_USER):$(DATABASE_PASSWORD)@$(DATABASE_HOST):5432/$(DATABASE_NAME)"
              - "--artifacts-destination"
              - "/mlflow/artifacts"
              - "--serve-artifacts"
              - "--host"
              - "0.0.0.0"
              - "--port"
              - "5000"
              - "--expose-prometheus"
              - "/tmp/prometheus"
              - "--allowed-hosts"
              - "*"
              resources:
                requests:
                  memory: "512Mi"
                  cpu: "250m"
                limits:
                  memory: "1Gi"
                  cpu: "500m"
              livenessProbe:
                httpGet:
                  path: /health
                  port: 5000
                initialDelaySeconds: 60
                periodSeconds: 20
                timeoutSeconds: 5
                failureThreshold: 5
              readinessProbe:
                httpGet:
                  path: /health
                  port: 5000
                initialDelaySeconds: 30
                periodSeconds: 10
                timeoutSeconds: 5
                failureThreshold: 5

  # MLflow Service - NodePort 30000
  - target:
      kind: Service
      name: mlflow-service
    patch: |-
      apiVersion: v1
      kind: Service
      metadata:
        name: mlflow-service
      spec:
        type: NodePort
        ports:
        - port: 5000
          targetPort: 5000
          nodePort: 30000

  # API - use locally built image
  - target:
      kind: Deployment
      name: ml-pipeline-api
    patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: ml-pipeline-api
      spec:
        replicas: 1
        template:
          spec:
            containers:
            - name: api
              image: ml-pipeline/api:v1.0.0
              imagePullPolicy: Never
              resources:
                requests:
                  memory: "256Mi"
                  cpu: "250m"
                limits:
                  memory: "512Mi"
                  cpu: "500m"
              livenessProbe:
                httpGet:
                  path: /health
                  port: 8000
                initialDelaySeconds: 60
                periodSeconds: 20
                timeoutSeconds: 5
                failureThreshold: 5
              readinessProbe:
                httpGet:
                  path: /health
                  port: 8000
                initialDelaySeconds: 30
                periodSeconds: 10
                timeoutSeconds: 5
                failureThreshold: 5
              volumeMounts:
              - name: mlflow-artifacts
                mountPath: /mlflow/artifacts
            volumes:
            - name: mlflow-artifacts
              persistentVolumeClaim:
                claimName: mlflow-pvc

  # API Service - NodePort 30001
  - target:
      kind: Service
      name: ml-pipeline-api-service
    patch: |-
      apiVersion: v1
      kind: Service
      metadata:
        name: ml-pipeline-api-service
      spec:
        type: NodePort
        ports:
        - name: http
          port: 8000
          targetPort: 8000
          protocol: TCP
          nodePort: 30001

  # Disable HPA for local single-replica testing
  - target:
      kind: HorizontalPodAutoscaler
      name: ml-pipeline-api-hpa
    patch: |-
      apiVersion: autoscaling/v2
      kind: HorizontalPodAutoscaler
      metadata:
        name: ml-pipeline-api-hpa
      spec:
        minReplicas: 1
        maxReplicas: 1

  # Grafana Service - NodePort 30002
  - target:
      kind: Service
      name: grafana-service
    patch: |-
      apiVersion: v1
      kind: Service
      metadata:
        name: grafana-service
      spec:
        type: NodePort
        ports:
        - port: 3000
          targetPort: 3000
          nodePort: 30002

  # Prometheus Service - NodePort 30090
  - target:
      kind: Service
      name: prometheus-service
    patch: |-
      apiVersion: v1
      kind: Service
      metadata:
        name: prometheus-service
      spec:
        type: NodePort
        ports:
        - port: 9090
          targetPort: 9090
          nodePort: 30090

  # Postgres - resource limits for Docker Desktop
  - target:
      kind: Deployment
      name: postgres
    patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: postgres
      spec:
        template:
          spec:
            containers:
            - name: postgres
              resources:
                requests:
                  memory: "256Mi"
                  cpu: "100m"
                limits:
                  memory: "512Mi"
                  cpu: "500m"

  # Redis - resource limits + password arg for Docker Desktop
  - target:
      kind: Deployment
      name: redis
    patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: redis
      spec:
        template:
          spec:
            containers:
            - name: redis
              args: ["--requirepass", "$(REDIS_PASSWORD)", "--maxmemory", "256mb", "--maxmemory-policy", "allkeys-lru"]
              resources:
                requests:
                  memory: "128Mi"
                  cpu: "50m"
                limits:
                  memory: "256Mi"
                  cpu: "250m"

  # Prometheus - resource limits for Docker Desktop
  - target:
      kind: Deployment
      name: prometheus
    patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: prometheus
      spec:
        template:
          spec:
            containers:
            - name: prometheus
              resources:
                requests:
                  memory: "128Mi"
                  cpu: "50m"
                limits:
                  memory: "256Mi"
                  cpu: "250m"

  # Grafana - resource limits for Docker Desktop
  - target:
      kind: Deployment
      name: grafana
    patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: grafana
      spec:
        template:
          spec:
            containers:
            - name: grafana
              resources:
                requests:
                  memory: "128Mi"
                  cpu: "50m"
                limits:
                  memory: "256Mi"
                  cpu: "100m"
