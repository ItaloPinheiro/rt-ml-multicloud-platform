# docker-compose.override.yml
# Local development configuration - automatically loaded with docker-compose.yml
# Usage: Simply run 'docker-compose up -d' (no -f flag needed)
# This file is automatically merged with docker-compose.yml when using 'docker-compose' commands

services:
  # =================================================================
  # Message Broker - Redpanda (Kafka-compatible)
  # =================================================================
  redpanda:
    image: docker.redpanda.com/redpandadata/redpanda:v23.3.3
    container_name: ml-redpanda
    ports:
      - "${REDPANDA_PORT:-9092}:9092"   # Kafka API
      - "9644:9644"   # Admin API
      - "${REDPANDA_CONSOLE_PORT:-8081}:8081"   # Schema Registry
      - "8082:8082"   # REST Proxy
    command:
      - redpanda
      - start
      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
      - --advertise-kafka-addr internal://redpanda:9092,external://localhost:19092
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      - --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      - --rpc-addr redpanda:33145
      - --advertise-rpc-addr redpanda:33145
      - --smp 1
      - --memory 1G
      - --mode dev-container
      - --default-log-level=info
    volumes:
      - redpanda_data:/var/lib/redpanda/data
    healthcheck:
      test: ["CMD-SHELL", "rpk cluster health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =================================================================
  # MLflow Database - PostgreSQL
  # =================================================================

  mlflow-db:
    image: postgres:16-alpine
    container_name: ml-mlflow-db
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-mlflow}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-mlflow123}
      POSTGRES_DB: ${POSTGRES_DB:-mlflow}
    ports:
      - "${POSTGRES_PORT:-5433}:5432"
    volumes:
      - mlflow_db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-mlflow}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =================================================================
  # MLflow Artifact Store - MinIO (S3-compatible)
  # =================================================================

  mlflow-minio:
    image: minio/minio:latest
    container_name: ml-mlflow-minio
    ports:
      - "${MINIO_PORT:-9000}:9000"   # API
      - "${MINIO_CONSOLE_PORT:-9001}:9001"   # Console
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin123}
    volumes:
      - mlflow_minio_data:/data
      - ../../ops/docker/scripts/minio-entrypoint.sh:/entrypoint.sh:ro
    entrypoint: /bin/sh /entrypoint.sh
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # =================================================================
  # MLflow Tracking Server - BUILD FROM LOCAL DOCKERFILE
  # =================================================================

  mlflow-server:
    build:
      context: ../../
      dockerfile: ops/docker/mlflow/Dockerfile
    container_name: ml-mlflow-server
    ports:
      - "${MLFLOW_PORT:-5000}:5000"
    environment:
      MLFLOW_BACKEND_STORE_URI: postgresql://${POSTGRES_USER:-mlflow}:${POSTGRES_PASSWORD:-mlflow123}@mlflow-db:5432/${POSTGRES_DB:-mlflow}
      MLFLOW_ARTIFACT_ROOT: ${MLFLOW_ARTIFACT_ROOT:-s3://mlflow/artifacts}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-minioadmin123}
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL:-http://mlflow-minio:9000}
      MLFLOW_HOST: 0.0.0.0
    depends_on:
      mlflow-db:
        condition: service_healthy
      mlflow-minio:
        condition: service_healthy
    command: >
      sh -c "
        mlflow server
        --host 0.0.0.0
        --port 5000
        --backend-store-uri postgresql://${POSTGRES_USER:-mlflow}:${POSTGRES_PASSWORD:-mlflow123}@mlflow-db:5432/${POSTGRES_DB:-mlflow}
        --default-artifact-root ${MLFLOW_ARTIFACT_ROOT:-s3://mlflow/artifacts}
        --no-serve-artifacts
        --workers 2
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =================================================================
  # Feature Store - Redis
  # =================================================================
  redis:
    image: redis:7-alpine
    container_name: ml-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =================================================================
  # Model API - BUILD FROM LOCAL DOCKERFILE
  # =================================================================

  ml-pipeline-api-service:
    build:
      context: ../../
      dockerfile: ops/docker/api/Dockerfile
    container_name: ml-pipeline-api-service
    ports:
      - "${API_PORT:-8000}:8000"
    environment:
      MLFLOW_TRACKING_URI: "${MLFLOW_TRACKING_URI:-http://mlflow-server:5000}"
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-minioadmin123}
      MLFLOW_S3_ENDPOINT_URL: "${MLFLOW_S3_ENDPOINT_URL:-http://mlflow-minio:9000}"
      MLFLOW_S3_IGNORE_TLS: "${MLFLOW_S3_IGNORE_TLS:-true}"
      AWS_S3_ADDRESSING_STYLE: "path"
      AWS_MAX_ATTEMPTS: "2"
      AWS_RETRY_MODE: "standard"
      MLFLOW_DOWNLOAD_CHUNK_SIZE: "10485760"
      MLFLOW_DOWNLOAD_ARTIFACT_TIMEOUT: "60"
      MLFLOW_DOWNLOAD_ARTIFACT_CACHE_DIR: "/model_cache"
      MODEL_CACHE_DIR: "/model_cache"
      REDIS_HOST: redis
      REDIS_PORT: 6379
      KAFKA_BOOTSTRAP_SERVERS: redpanda:9092
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      API_RELOAD: "${API_RELOAD:-false}"
      PRELOAD_MODELS: "${PRELOAD_MODELS:-fraud_detector:latest}"
      MODEL_AUTO_UPDATE: "${MODEL_AUTO_UPDATE:-true}"
      MODEL_UPDATE_INTERVAL: "${MODEL_UPDATE_INTERVAL:-60}"
    depends_on:
      mlflow-server:
        condition: service_healthy
      redis:
        condition: service_healthy
      redpanda:
        condition: service_healthy
    volumes:
      - ../../src:/app/src
      - ../../model_cache:/model_cache
      - ../../configs:/app/configs
      - ../../scripts:/app/scripts
      - ../../sample_data:/app/sample_data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =================================================================
  # Monitoring - Prometheus
  # =================================================================

  prometheus:
    image: prom/prometheus:latest
    container_name: ml-prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ../../ops/monitoring/prometheus/prometheus-local.yml:/etc/prometheus/prometheus.yml:ro
      - ../../ops/monitoring/prometheus/alerts/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - ../../ops/monitoring/prometheus/rules/recording_rules.yml:/etc/prometheus/recording_rules.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =================================================================
  # Monitoring - Grafana
  # =================================================================

  grafana:
    image: grafana/grafana:latest
    container_name: ml-grafana
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin123}
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-worldmap-panel
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - ../../ops/monitoring/grafana/dashboards/dashboards.yaml:/etc/grafana/provisioning/dashboards/dashboards.yaml:ro
      - ../../ops/monitoring/grafana/datasources/datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml:ro
      - ../../ops/monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana_data:/var/lib/grafana
    depends_on:
      prometheus:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # =================================================================
  # Redis Exporter - Prometheus metrics for Redis
  # =================================================================
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: ml-redis-exporter
    ports:
      - "9121:9121"
    environment:
      REDIS_ADDR: redis:6379
    depends_on:
      redis:
        condition: service_healthy

  # =================================================================
  # PostgreSQL Exporter - Prometheus metrics for PostgreSQL
  # =================================================================

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: ml-postgres-exporter
    ports:
      - "9187:9187"
    environment:
      DATA_SOURCE_NAME: postgresql://${POSTGRES_USER:-mlflow}:${POSTGRES_PASSWORD:-mlflow123}@mlflow-db:5432/${POSTGRES_DB:-mlflow}?sslmode=disable
    depends_on:
      mlflow-db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9187/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =================================================================
  # Apache Beam Runner - BUILD FROM LOCAL DOCKERFILE (optional profile)
  # =================================================================
  beam-runner:
    build:
      context: ../../
      dockerfile: ops/docker/beam/Dockerfile
    container_name: ml-beam-runner
    environment:
      BEAM_RUNNER: DirectRunner
      GCP_PROJECT: ${GCP_PROJECT:-local-project}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      PYTHONPATH: /app
      MLFLOW_TRACKING_URI: http://mlflow-server:5000
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-minioadmin123}
      MLFLOW_S3_ENDPOINT_URL: http://mlflow-minio:9000
    volumes:
      - ../../src:/app/src:ro
      - ../../data:/app/data
      - ../../configs:/app/configs:ro
      - ../../sample_data:/app/sample_data
      - ../../scripts:/app/scripts:ro
    depends_on:
      redpanda:
        condition: service_healthy
    profiles:
      - beam  # Only start with --profile beam

# =================================================================
# Persistent Volumes
# =================================================================
volumes:
  redpanda_data:
    driver: local
  mlflow_db_data:
    driver: local
  mlflow_minio_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# =================================================================
# Networks
# =================================================================
networks:
  default:
    name: ml-pipeline-network
    driver: bridge
