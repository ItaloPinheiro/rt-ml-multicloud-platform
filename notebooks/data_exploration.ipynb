{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - ML Pipeline Platform\n",
    "\n",
    "Quick exploration of transaction data for fraud detection model.\n",
    "\n",
    "**Purpose**: Validate data quality and identify key features for the ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', 10)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print(\"Environment ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data or generate if not exists\n",
    "data_path = Path('../sample_data/demo/datasets/fraud_detection.csv')\n",
    "\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Loaded {len(df)} transactions from {data_path}\")\n",
    "else:\n",
    "    # Generate sample data if file doesn't exist\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'amount': np.random.lognormal(4, 2, n_samples),\n",
    "        'merchant_category': np.random.choice(['electronics', 'grocery', 'gas', 'restaurant', 'online'], n_samples),\n",
    "        'hour_of_day': np.random.randint(0, 24, n_samples),\n",
    "        'is_weekend': np.random.choice([0, 1], n_samples),\n",
    "        'risk_score': np.random.beta(2, 5, n_samples),\n",
    "        'days_since_last': np.random.exponential(5, n_samples),\n",
    "        'num_transactions_today': np.random.poisson(3, n_samples),\n",
    "        'label': np.random.choice([0, 1], n_samples, p=[0.95, 0.05])  # 5% fraud rate\n",
    "    })\n",
    "\n",
    "    # Make fraud transactions look different\n",
    "    fraud_idx = df['label'] == 1\n",
    "    df.loc[fraud_idx, 'risk_score'] *= 2\n",
    "    df.loc[fraud_idx, 'amount'] *= 1.5\n",
    "\n",
    "    print(f\"Generated {len(df)} sample transactions\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality summary\n",
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "print(f\"\\nFraud rate: {df['label'].mean()*100:.1f}%\")\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nNumerical features summary:\")\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key feature distributions by fraud label\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Amount distribution\n",
    "for label in [0, 1]:\n",
    "    data = df[df['label'] == label]['amount']\n",
    "    axes[0,0].hist(data, alpha=0.6, label=f\"{'Fraud' if label else 'Normal'}\", bins=20)\n",
    "axes[0,0].set_xlabel('Transaction Amount')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].set_title('Amount Distribution')\n",
    "\n",
    "# Risk score distribution\n",
    "for label in [0, 1]:\n",
    "    data = df[df['label'] == label]['risk_score']\n",
    "    axes[0,1].hist(data, alpha=0.6, label=f\"{'Fraud' if label else 'Normal'}\", bins=20)\n",
    "axes[0,1].set_xlabel('Risk Score')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].set_title('Risk Score Distribution')\n",
    "\n",
    "# Merchant category fraud rates\n",
    "fraud_by_merchant = df.groupby('merchant_category')['label'].mean()\n",
    "axes[1,0].bar(fraud_by_merchant.index, fraud_by_merchant.values)\n",
    "axes[1,0].set_xlabel('Merchant Category')\n",
    "axes[1,0].set_ylabel('Fraud Rate')\n",
    "axes[1,0].set_title('Fraud Rate by Merchant')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hour of day patterns\n",
    "hourly_fraud = df.groupby('hour_of_day')['label'].mean()\n",
    "axes[1,1].plot(hourly_fraud.index, hourly_fraud.values, 'o-')\n",
    "axes[1,1].set_xlabel('Hour of Day')\n",
    "axes[1,1].set_ylabel('Fraud Rate')\n",
    "axes[1,1].set_title('Fraud Rate by Hour')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key observations:\")\n",
    "print(f\"‚Ä¢ Fraud transactions have {df[df['label']==1]['amount'].mean()/df[df['label']==0]['amount'].mean():.1f}x higher amounts\")\n",
    "print(f\"‚Ä¢ Risk score for fraud: {df[df['label']==1]['risk_score'].mean():.3f} vs normal: {df[df['label']==0]['risk_score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Calculate correlations with fraud label\n",
    "fraud_correlations = df[numerical_cols].corr()['label'].sort_values(ascending=False)\n",
    "\n",
    "print(\"Feature Correlations with Fraud Label:\")\n",
    "print(\"=\"*40)\n",
    "for feature, corr in fraud_correlations.items():\n",
    "    if feature != 'label':\n",
    "        print(f\"{feature:25s}: {corr:+.3f}\")\n",
    "\n",
    "# Visual correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(df[numerical_cols].corr(), annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived features\n",
    "df['amount_log'] = np.log1p(df['amount'])\n",
    "df['risk_amount_interaction'] = df['risk_score'] * df['amount']\n",
    "df['high_risk'] = (df['risk_score'] > df['risk_score'].quantile(0.75)).astype(int)\n",
    "df['unusual_hour'] = df['hour_of_day'].apply(lambda x: 1 if x < 6 or x > 22 else 0)\n",
    "\n",
    "# Evaluate new features\n",
    "new_features = ['amount_log', 'risk_amount_interaction', 'high_risk', 'unusual_hour']\n",
    "new_correlations = df[new_features + ['label']].corr()['label'].sort_values(ascending=False)\n",
    "\n",
    "print(\"Engineered Feature Correlations:\")\n",
    "print(\"=\"*40)\n",
    "for feature, corr in new_correlations.items():\n",
    "    if feature != 'label':\n",
    "        print(f\"{feature:25s}: {corr:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Readiness Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL READINESS ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Data readiness checklist\n",
    "checklist = {\n",
    "    \"Sufficient data\": len(df) >= 1000,\n",
    "    \"No missing values\": df.isnull().sum().sum() == 0,\n",
    "    \"Balanced classes\": df['label'].mean() > 0.01 and df['label'].mean() < 0.5,\n",
    "    \"Feature variation\": df.std().min() > 0,\n",
    "    \"Numerical features\": len(df.select_dtypes(include=[np.number]).columns) >= 3,\n",
    "}\n",
    "\n",
    "print(\"\\nData Quality Checklist:\")\n",
    "for check, passed in checklist.items():\n",
    "    status = \"‚úÖ\" if passed else \"‚ùå\"\n",
    "    print(f\"  {status} {check}\")\n",
    "\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"  ‚Ä¢ Records: {len(df):,}\")\n",
    "print(f\"  ‚Ä¢ Features: {len(df.columns)-1}\")\n",
    "print(f\"  ‚Ä¢ Fraud rate: {df['label'].mean()*100:.1f}%\")\n",
    "print(f\"  ‚Ä¢ Memory usage: {df.memory_usage(deep=True).sum()/1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\nüéØ Recommended Features for Model:\")\n",
    "top_features = fraud_correlations.abs().nlargest(6).index.tolist()\n",
    "top_features = [f for f in top_features if f != 'label']\n",
    "for i, feature in enumerate(top_features, 1):\n",
    "    print(f\"  {i}. {feature} (correlation: {fraud_correlations[feature]:+.3f})\")\n",
    "\n",
    "print(\"\\n‚úÖ Data is ready for model training!\")\n",
    "print(\"\\nNext step: Run model_training_analysis.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export preprocessed data for model training\n",
    "output_path = Path('../sample_data/demo/datasets')\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the enhanced dataset\n",
    "df.to_csv(output_path / 'fraud_detection_processed.csv', index=False)\n",
    "print(f\"\\nüíæ Saved processed data to {output_path / 'fraud_detection_processed.csv'}\")\n",
    "print(f\"Features saved: {', '.join(df.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}